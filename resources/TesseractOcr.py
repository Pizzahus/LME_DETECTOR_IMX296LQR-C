import queue
import pytesseract
import time
import numpy as np
import cv2
from PySide6.QtCore import QThread, Signal
from resources.FramePreprocessor import FramePreprocessor

pytesseract.pytesseract.tesseract_cmd = r"/usr/bin/tesseract"

# ===== Worker OCR (Queue-based) =====
class OcrWorker(QThread):
    finished = Signal(np.ndarray, np.ndarray, np.ndarray, str, float)  # à¸–à¹‰à¸² import numpy as np à¹à¸¥à¹‰à¸§

    def __init__(self, task_queue, angle=0, confidence=0):
        super().__init__()
        self.task_queue = task_queue
        self.rectColor = (255, 17, 0)
        self.running = True
        self.angle=angle
        self.confidence=confidence
        self.preprocessor = FramePreprocessor()

    
    def rotate_image_cover(self, image, angle):
        (h, w) = image.shape[:2]
        center = (w // 2, h // 2)

        # à¸ªà¸£à¹‰à¸²à¸‡ matrix à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸«à¸¡à¸¸à¸™
        M = cv2.getRotationMatrix2D(center, angle, 1.0)

        # à¸„à¸³à¸™à¸§à¸“à¸‚à¸™à¸²à¸”à¹ƒà¸«à¸¡à¹ˆà¸‚à¸­à¸‡ canvas
        cos = np.abs(M[0, 0])
        sin = np.abs(M[0, 1])
        new_w = int((h * sin) + (w * cos))
        new_h = int((h * cos) + (w * sin))

        # à¸›à¸£à¸±à¸š matrix à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸ à¸²à¸žà¸­à¸¢à¸¹à¹ˆà¸•à¸£à¸‡à¸à¸¥à¸²à¸‡ canvas à¹ƒà¸«à¸¡à¹ˆ
        M[0, 2] += (new_w / 2) - center[0]
        M[1, 2] += (new_h / 2) - center[1]

        # à¸«à¸¡à¸¸à¸™à¸ à¸²à¸žà¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ canvas à¹ƒà¸«à¸¡à¹ˆ
        rotated = cv2.warpAffine(image, M, (new_w, new_h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)
        return rotated
    
    # à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¹ƒà¸«à¹‰à¹à¸ªà¸”à¸‡à¸ à¸²à¸žà¸—à¸µà¹ˆà¸ˆà¸±à¸šà¹„à¸”à¹‰
    def detect_and_recognize_text(self, image):
        """
        image: à¸ à¸²à¸ž BGR
        angle: à¸«à¸¡à¸¸à¸™à¸ à¸²à¸žà¸à¹ˆà¸­à¸™ OCR (à¸­à¸‡à¸¨à¸², +ve = à¸«à¸¡à¸¸à¸™à¸•à¸²à¸¡à¹€à¸‚à¹‡à¸¡à¸™à¸²à¸¬à¸´à¸à¸²)
        """
        start = time.perf_counter()

        original_image = image.copy()  # à¹€à¸à¹‡à¸šà¸ à¸²à¸žà¸•à¹‰à¸™à¸‰à¸šà¸±à¸šà¹„à¸§à¹‰à¸à¹ˆà¸­à¸™à¹à¸à¹‰à¹„à¸‚

        # à¸«à¸¡à¸¸à¸™à¸ à¸²à¸žà¸–à¹‰à¸²à¸¡à¸µà¸à¸²à¸£à¸£à¸°à¸šà¸¸ angle
        if self.angle != 0:
            image = self.rotate_image_cover(image, self.angle)

        # à¹à¸›à¸¥à¸‡à¹€à¸›à¹‡à¸™ grayscale à¹à¸¥à¸°à¸—à¸³ preprocessing
        preprocessed_image = self.preprocessor.process(image)

        # à¹ƒà¸Šà¹‰ Pytesseract à¸­à¹ˆà¸²à¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡ OCR à¸žà¸£à¹‰à¸­à¸¡à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡
        config = (
            r"--oem 1 --psm 6 "
            r"-c tessedit_char_whitelist=0123456789/ABCDEFGHIJKLMNOPQRSTUVWXYZ"
        )
        data = pytesseract.image_to_data(preprocessed_image, lang="eng_best", output_type=pytesseract.Output.DICT)

        # à¸§à¸²à¸”à¸à¸£à¸­à¸šà¸£à¸­à¸šà¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¹à¸¥à¸°à¸à¸£à¸­à¸‡à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ
        filtered_results = []
        for i in range(len(data["text"])):
            text = data["text"][i]
            confidence = int(data["conf"][i])
            if confidence > self.confidence and text.strip():
                filtered_results.append(text)
                x, y, w, h = data["left"][i], data["top"][i], data["width"][i], data["height"][i]
                char_width = w / len(text)
                for j, char in enumerate(text):
                    char_x = int(x + j * char_width)
                    char_w = int(char_width)
                    cv2.rectangle(image, (char_x, y), (char_x + char_w, y + h), self.rectColor, 1)
                    cv2.putText(image, char, (char_x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, self.rectColor, 1)

        recognized_text = " ".join(filtered_results)
        processed_image = image
        processing_time = time.perf_counter() - start

        # à¹à¸›à¸¥à¸‡à¹€à¸§à¸¥à¸²à¹€à¸›à¹‡à¸™ ms
        processing_ms = processing_time * 1000
        time_text = f"Processing Time: {processing_ms:.1f}ms"

        # à¸‚à¸™à¸²à¸”à¸ à¸²à¸ž
        img_height, img_width = processed_image.shape[:2]

        # à¸›à¸£à¸±à¸šà¸‚à¸™à¸²à¸”à¸Ÿà¸­à¸™à¸•à¹Œà¸•à¸²à¸¡à¸„à¸§à¸²à¸¡à¸ªà¸¹à¸‡à¸‚à¸­à¸‡à¸ à¸²à¸ž
        font_scale = img_height / 350.0
        thickness = max(1, int(img_height / 100))

        # à¸„à¸³à¸™à¸§à¸“à¸‚à¸™à¸²à¸”à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡
        (text_width, text_height), _ = cv2.getTextSize(time_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)

        # à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸à¸¶à¹ˆà¸‡à¸à¸¥à¸²à¸‡à¸”à¹‰à¸²à¸™à¸¥à¹ˆà¸²à¸‡
        text_x = (img_width - text_width) // 2
        text_y = img_height - 15

        # ðŸ§  à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸ªà¸µà¸žà¸·à¹‰à¸™à¸«à¸¥à¸±à¸‡à¹ƒà¸•à¹‰à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡
        roi_y1 = max(0, text_y - text_height)
        roi_y2 = min(img_height, text_y + 5)
        roi_x1 = max(0, text_x)
        roi_x2 = min(img_width, text_x + text_width)
        roi = processed_image[roi_y1:roi_y2, roi_x1:roi_x2]

        # à¸„à¸³à¸™à¸§à¸“à¸„à¸§à¸²à¸¡à¸ªà¸§à¹ˆà¸²à¸‡à¹€à¸‰à¸¥à¸µà¹ˆà¸¢
        brightness = int(np.mean(roi)) if roi.size > 0 else 128

        # à¹€à¸¥à¸·à¸­à¸à¸ªà¸µà¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¹ƒà¸«à¹‰à¸•à¸±à¸”à¸à¸±à¸™
        text_color = (0, 0, 0) if brightness > 128 else (255, 255, 255)

        # à¸§à¸²à¸”à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡
        cv2.putText(processed_image, time_text, (text_x, text_y),
                    cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_color, thickness)



        return (original_image, processed_image, preprocessed_image, recognized_text, processing_time)

    def run(self):
        while self.running:
            try:
                frame = self.task_queue.get(timeout=0.1)
            except queue.Empty:
                continue

            original_image, processed_image, preprocessed_image, recognized_text, processing_time = self.detect_and_recognize_text(frame)
            self.finished.emit(original_image, processed_image, preprocessed_image, recognized_text, processing_time)
            self.task_queue.task_done()

    def stop(self):
        self.running = False
        self.wait()